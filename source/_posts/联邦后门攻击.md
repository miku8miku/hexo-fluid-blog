---
title: 联邦后门攻击
date: 2024-06-29 13:49
index_img: https://api.qjqq.cn/api/bingimg
category: 博文
tags:
  - 科研
  - 联邦学习
math: true
mermaid: true
# sticky: 1 # 置顶
---
>联邦学习与后门攻击结合的论文

<!-- more -->

### Federated Learning
- FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning.
  [[pdf]](https://openreview.net/pdf?id=Xo2E217_M4n)
  [[code]](https://github.com/KaiyuanZh/FLIP)
  - Kaiyuan Zhang, Guanhong Tao, Qiuling Xu, Siyuan Cheng, Shengwei An, Yingqi Liu, Shiwei Feng, Guangyu Shen, Pin-Yu Chen, Shiqing Ma, and Xiangyu Zhang. *ICLR*, 2023.

- On the Vulnerability of Backdoor Defenses for Federated Learning.
  [[link]](https://ojs.aaai.org/index.php/AAAI/article/view/26393)
  [[code]](https://github.com/jinghuichen/Focused-Flip-Federated-Backdoor-Attack)
  - Pei Fang and Jinghui Chen. *AAAI*, 2023.

- Poisoning with Cerberus: Stealthy and Colluded Backdoor Attack against Federated Learning.
  [[link]](https://ojs.aaai.org/index.php/AAAI/article/view/26083)
  - Xiaoting Lyu, Yufei Han, Wei Wang, Jingkai Liu, Bin Wang, Jiqiang Liu, and Xiangliang Zhang. *AAAI*, 2023.

- Neurotoxin: Durable Backdoors in Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2206.10341.pdf)
  - Zhengming Zhang, Ashwinee Panda, Linyue Song, Yaoqing Yang, Michael W. Mahoney, Joseph E. Gonzalez, Kannan Ramchandran, and Prateek Mittal. *ICML*, 2022.

- FLAME: Taming Backdoors in Federated Learning.
  [[pdf]](https://www.usenix.org/system/files/sec22fall_nguyen.pdf)
  - Thien Duc Nguyen, Phillip Rieger, Huili Chen, Hossein Yalame, Helen Möllering, Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini, Shaza Zeitouni, Farinaz Koushanfar, Ahmad-Reza Sadeghi, and Thomas Schneider. *USENIX Security*, 2022.

- DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection.
  [[pdf]](https://arxiv.org/pdf/2201.00763.pdf)
  - Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, and Ahmad-Reza Sadeghi. *NDSS*, 2022.

- Defending Label Inference and Backdoor Attacks in Vertical Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2112.05409.pdf)
  - Yang Liu, Zhihao Yi, Yan Kang, Yuanqin He, Wenhan Liu, Tianyuan Zou, and Qiang Yang. *AAAI*, 2022.

- An Analysis of Byzantine-Tolerant Aggregation Mechanisms on Model Poisoning in Federated Learning.
  [[link]](https://link.springer.com/chapter/10.1007/978-3-031-13448-7_12)
  - Mary Roszel, Robert Norvill, and Radu State. *MDAI*, 2022.

- Against Backdoor Attacks In Federated Learning With Differential Privacy.
  [[link]](https://ieeexplore.ieee.org/abstract/document/9747653)
  - Lu Miao, Wei Yang, Rong Hu, Lu Li, and Liusheng Huang. *ICASSP*, 2022.

- Secure Partial Aggregation: Making Federated Learning More Robust for Industry 4.0 Applications.
  [[link]](https://ieeexplore.ieee.org/abstract/document/9692911)
  - Jiqiang Gao, Baolei Zhang, Xiaojie Guo, Thar Baker, Min Li, and Zheli Liu. *IEEE Transactions on Industrial Informatics*, 2022.

- Backdoor Attacks-resilient Aggregation based on Robust Filtering of Outliers in Federated Learning for Image Classification.
  [[link]](https://www.sciencedirect.com/science/article/pii/S0950705122002635)
  - Nuria Rodríguez-Barroso, Eugenio Martínez-Cámara, M. Victoria Luzónb, and Francisco Herrera. *Knowledge-Based Systems*, 2022.

- Defense against Backdoor Attack in Federated Learning.
  [[link]](https://www.sciencedirect.com/science/article/pii/S0167404822002139)
  [[code]](https://github.com/lsw3130104597/Backdoor_detection)
  - Shiwei Lu, Ruihu Li, Wenbin Liu, and Xuan Chen. *Computers & Security*, 2022.

- Privacy-Enhanced Federated Learning against Poisoning Adversaries.
  [[link]](https://ieeexplore.ieee.org/abstract/document/9524709/)
  - Xiaoyuan Liu, Hongwei Li, Guowen Xu, Zongqi Chen, Xiaoming Huang, and Rongxing Lu. *IEEE Transactions on Information Forensics and Security*, 2021.

- Coordinated Backdoor Attacks against Federated Learning with Model-Dependent Triggers.
  [[link]](https://ieeexplore.ieee.org/abstract/document/9713908)
  - Xueluan Gong, Yanjiao Chen, Huayang Huang, Yuqing Liao, Shuai Wang, and Qian Wang. *IEEE Network*, 2022.

- CRFL: Certifiably Robust Federated Learning against Backdoor Attacks.
  [[pdf]](https://arxiv.org/pdf/2106.08283.pdf)
  - Chulin Xie, Minghao Chen, Pin-Yu Chen, and Bo Li. *ICML*, 2021.

- Curse or Redemption? How Data Heterogeneity Affects the Robustness of Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2102.00655.pdf)
  - Syed Zawad, Ahsan Ali, Pin-Yu Chen, Ali Anwar, Yi Zhou, Nathalie Baracaldo, Yuan Tian, and Feng Yan. *AAAI*, 2021.

- Defending Against Backdoors in Federated Learning with Robust Learning Rate.
  [[pdf]](https://arxiv.org/pdf/2007.03767.pdf)
  - Mustafa Safa Ozdayi, Murat Kantarcioglu, and Yulia R. Gel. *AAAI*, 2021.
  
- BaFFLe: Backdoor detection via Feedback-based Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2011.02167.pdf)
  - ebastien Andreina, Giorgia Azzurra Marson, Helen Möllering, and Ghassan Karame. *ICDCS*, 2021.

- PipAttack: Poisoning Federated Recommender Systems for Manipulating Item Promotion.
  [[pdf]](https://arxiv.org/pdf/2110.10926.pdf)
  - Shijie Zhang, Hongzhi Yin, Tong Chen, Zi Huang, Quoc Viet Hung Nguyen, and Lizhen Cui. *WSDM*, 2021.

- Mitigating the Backdoor Attack by Federated Filters for Industrial IoT Applications.
  [[link]](https://ieeexplore.ieee.org/document/9536411/)
  - Boyu Hou, Jiqiang Gao, Xiaojie Guo, Thar Baker, Ying Zhang, Yanlong Wen, and Zheli Liu. *IEEE Transactions on Industrial Informatics*, 2021.

- Stability-Based Analysis and Defense against Backdoor Attacks on Edge Computing Services.
  [[link]](https://ieeexplore.ieee.org/abstract/document/9354927)
  - Yi Zhao, Ke Xu, Haiyang Wang, Bo Li, and Ruoxi Jia. *IEEE Network*, 2021.

- Attack of the Tails: Yes, You Really Can Backdoor Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2007.05084.pdf)
  - Hongyi Wang, Kartik Sreenivasan, Shashank Rajput, Harit Vishwakarma, Saurabh Agarwal, Jy-yong Sohn, Kangwook Lee, and Dimitris Papailiopoulos. *NeurIPS*, 2020.
  
- DBA: Distributed Backdoor Attacks against Federated Learning.
  [[pdf]](https://openreview.net/pdf?id=rkgyS0VFvr)
  - Chulin Xie, Keli Huang, Pinyu Chen, and Bo Li. *ICLR*, 2020.


- The Limitations of Federated Learning in Sybil Settings.
  [[pdf]](https://www.cs.ubc.ca/~bestchai/papers/foolsgold-raid2020.pdf)
  [[extension]](https://arxiv.org/pdf/1808.04866.pdf)
  [[code]](https://github.com/DistributedML/FoolsGold)
  - Clement Fung, Chris J.M. Yoon, and Ivan Beschastnikh. *RAID*, 2020 (arXiv, 2018).

- How to Backdoor Federated Learning.
  [[pdf]](https://arxiv.org/pdf/1807.00459.pdf)
  - Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly Shmatikov. *AISTATS*, 2020 (arXiv, 2018).


- BEAS: Blockchain Enabled Asynchronous & Secure Federated Machine Learning.
  [[pdf]](https://arxiv.org/pdf/2202.02817.pdf)
  - Arup Mondal, Harpreet Virk, and Debayan Gupta. *AAAI Workshop*, 2022.
  
- Backdoor Attacks and Defenses in Feature-partitioned Collaborative Learning.
  [[pdf]](https://arxiv.org/pdf/2007.03608.pdf)
  - Yang Liu, Zhihao Yi, and Tianjian Chen. *ICML Workshop*, 2020.

- Can You Really Backdoor Federated Learning?
  [[pdf]](https://arxiv.org/pdf/1911.07963.pdf)
  - Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, and H. Brendan McMahan. *NeurIPS Workshop*, 2019.

- Invariant Aggregator for Defending Federated Backdoor Attacks.
  [[pdf]](https://arxiv.org/pdf/2210.01834.pdf)
  - Xiaoyang Wang, Dimitrios Dimitriadis, Sanmi Koyejo, and Shruti Tople. arXiv, 2022.

- Shielding Federated Learning: Mitigating Byzantine Attacks with Less Constraints.
  [[pdf]](https://arxiv.org/pdf/2210.01437.pdf)
  - Minghui Li, Wei Wan, Jianrong Lu, Shengshan Hu, Junyu Shi, and Leo Yu Zhang. arXiv, 2022.

- Federated Zero-Shot Learning for Visual Recognition.
  [[pdf]](https://arxiv.org/pdf/2209.01994.pdf)
  - Zhi Chen, Yadan Luo, Sen Wang, Jingjing Li, and Zi Huang. arXiv, 2022.

- Assisting Backdoor Federated Learning with Whole Population Knowledge Alignment.
  [[pdf]](https://arxiv.org/pdf/2207.12327.pdf)
  - Tian Liu, Xueyang Hu, and Tao Shu. arXiv, 2022.

- FL-Defender: Combating Targeted Attacks in Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2207.00872.pdf)
  - Najeeb Jebreel and Josep Domingo-Ferrer. arXiv, 2022.

- Backdoor Attack is A Devil in Federated GAN-based Medical Image Synthesis.
  [[pdf]](https://arxiv.org/pdf/2207.00762.pdf)
  - Ruinan Jin and Xiaoxiao Li. arXiv, 2022.

- SafeNet: Mitigating Data Poisoning Attacks on Private Machine Learning.
  [[pdf]](https://arxiv.org/pdf/2205.09986.pdf)
  [[code]](https://github.com/data61/MP-SPDZ)
  - Harsh Chaudhari, Matthew Jagielski, and Alina Oprea. arXiv, 2022.

- PerDoor: Persistent Non-Uniform Backdoors in Federated Learning using Adversarial Perturbations.
  [[pdf]](https://arxiv.org/pdf/2205.13523.pdf)
  [[code]](https://github.com/momalab/PerDoor)
  - Manaar Alam, Esha Sarkar, and Michail Maniatakos. arXiv, 2022.

- Towards a Defense against Backdoor Attacks in Continual Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2205.11736.pdf)
  - Shuaiqi Wang, Jonathan Hayase, Giulia Fanti, and Sewoong Oh. arXiv, 2022.
  
- Client-Wise Targeted Backdoor in Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2203.08689.pdf)
  - Gorka Abad, Servio Paguada, Stjepan Picek, Víctor Julio Ramírez-Durán, and Aitor Urbieta. arXiv, 2022.

- Backdoor Defense in Federated Learning Using Differential Testing and Outlier Detection.
  [[pdf]](https://arxiv.org/pdf/2202.11196.pdf)
  - Yein Kim, Huili Chen, and Farinaz Koushanfar. arXiv, 2022.

- ARIBA: Towards Accurate and Robust Identification of Backdoor Attacks in Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2202.04311.pdf)
  - Yuxi Mi, Jihong Guan, and Shuigeng Zhou. arXiv, 2022.

- More is Better (Mostly): On the Backdoor Attacks in Federated Graph Neural Networks.
  [[pdf]](https://arxiv.org/pdf/2202.03195.pdf)
  - Jing Xu, Rui Wang, Kaitai Liang, and Stjepan Picek. arXiv, 2022.

- Low-Loss Subspace Compression for Clean Gains against Multi-Agent Backdoor Attacks.
  [[pdf]](https://arxiv.org/pdf/2203.03692.pdf)
  - Siddhartha Datta and Nigel Shadbolt. arXiv, 2022.

- Backdoors Stuck at The Frontdoor: Multi-Agent Backdoor Attacks That Backfire.
  [[pdf]](https://arxiv.org/pdf/2201.12211.pdf)
  - Siddhartha Datta and Nigel Shadbolt. arXiv, 2022.

- Federated Unlearning with Knowledge Distillation.
  [[pdf]](https://arxiv.org/pdf/2201.09441.pdf)
  - Chen Wu, Sencun Zhu, and Prasenjit Mitra. arXiv, 2022.

- Model Transferring Attacks to Backdoor HyperNetwork in Personalized Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2201.07063.pdf)
  - Phung Lai, NhatHai Phan, Abdallah Khreishah, Issa Khalil, and Xintao Wu. arXiv, 2022.

- Backdoor Attacks on Federated Learning with Lottery Ticket Hypothesis.
  [[pdf]](https://arxiv.org/pdf/2109.10512.pdf)
  - Zihang Zou, Boqing Gong, and Liqiang Wang. arXiv, 2021.

- On Provable Backdoor Defense in Collaborative Learning.
  [[pdf]](https://arxiv.org/pdf/2101.08177.pdf)
  - Ximing Qiao, Yuhua Bai, Siping Hu, Ang Li, Yiran Chen, and Hai Li. arXiv, 2021.

- SparseFed: Mitigating Model Poisoning Attacks in Federated Learning with Sparsification.
  [[pdf]](https://arxiv.org/pdf/2112.06274.pdf)
  - Ashwinee Panda, Saeed Mahloujifar, Arjun N. Bhagoji, Supriyo Chakraborty, and Prateek Mittal. arXiv, 2021.

- Robust Federated Learning with Attack-Adaptive Aggregation.
  [[pdf]](https://arxiv.org/pdf/2102.05257.pdf)
  [[code]](https://github.com/cpwan/Attack-Adaptive-Aggregation)
  - Ching Pui Wan, and Qifeng Chen. arXiv, 2021.

- Meta Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2102.05561.pdf)
  - Omid Aramoon, Pin-Yu Chen, Gang Qu, and Yuan Tian. arXiv, 2021.

- FLGUARD: Secure and Private Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2101.02281.pdf)
  - Thien Duc Nguyen, Phillip Rieger, Hossein Yalame, Helen Möllering, Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini, Ahmad-Reza Sadeghi, Thomas Schneider, and Shaza Zeitouni. arXiv, 2021.

- Toward Robustness and Privacy in Federated Learning: Experimenting with Local and Central Differential Privacy.
  [[pdf]](https://arxiv.org/pdf/2009.03561.pdf)
  - Mohammad Naseri, Jamie Hayes, and Emiliano De Cristofaro. arXiv, 2020.

- Backdoor Attacks on Federated Meta-Learning. 
  [[pdf]](https://arxiv.org/pdf/2006.07026.pdf)
  - Chien-Lun Chen, Leana Golubchik, and Marco Paolieri. arXiv, 2020. 

- Dynamic backdoor attacks against federated learning.
  [[pdf]](https://arxiv.org/pdf/2011.07429.pdf)
  - Anbu Huang. arXiv, 2020.

- Federated Learning in Adversarial Settings.
  [[pdf]](https://arxiv.org/pdf/2010.07808.pdf)
  - Raouf Kerkouche, Gergely Ács, and Claude Castelluccia. arXiv, 2020.

- BlockFLA: Accountable Federated Learning via Hybrid Blockchain Architecture.
  [[pdf]](https://arxiv.org/pdf/2010.07427.pdf)
  - Harsh Bimal Desai, Mustafa Safa Ozdayi, and Murat Kantarcioglu. arXiv, 2020.

- Mitigating Backdoor Attacks in Federated Learning.
  [[pdf]](https://arxiv.org/pdf/2011.01767.pdf)
  - Chen Wu, Xian Yang, Sencun Zhu, and Prasenjit Mitra. arXiv, 2020.

- Learning to Detect Malicious Clients for Robust Federated Learning. 
  [[pdf]](https://arxiv.org/pdf/2002.00211.pdf)
  - Suyi Li, Yong Cheng, Wei Wang, Yang Liu, and Tianjian Chen. arXiv, 2020.
  
- Attack-Resistant Federated Learning with Residual-based Reweighting.
  [[pdf]](https://arxiv.org/pdf/1912.11464.pdf)
  [[code]](https://github.com/fushuhao6/Attack-Resistant-Federated-Learning)
  - Shuhao Fu, Chulin Xie, Bo Li, and Qifeng Chen. arXiv, 2019.